<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MVDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors">
  <meta name="keywords" content="MVDrag3D, 3D AIGC, 3D Editing, 3D Generative Model, Multi-view Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MVDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors.</title>

  <style>
    .dnerf {
        font-size: 36px; /* Adjust the size as needed */
    }
  </style>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"> -->

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <!-- <link rel="stylesheet" href="./static/css/index.css"> -->
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <span class="dnerf">MVDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors</span>
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://chenhonghua.github.io/clay.github.io/">Honghua Chen, </a></span>
              <!--  -->
              <span class="author-block">
                <a href="https://nirvanalan.github.io/">Yushi Lan, </a></span>

              <span class="author-block">
                <a href="https://cyw-3d.github.io/">Yongwei Chen, </a></span>

              <span class="author-block">
                <a href="https://zhouyifan.net/">Yifan Zhou, </a></span>

              <span class="author-block">
                <a href="https://xingangpan.github.io/">Xingang Pan</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">S-Lab, Nanyang Technological University, Singapore</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.16272" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/chenhonghua/MvDrag3D" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code coming soon</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span> -->
                <!-- </a> -->
              </div>



              <hr style="width:100%;height:0.7px;background-color:rgba(0, 0, 0, 0.665);margin-top:1em">
              
              <font size="5">
                <b>MvDrag3D</b> provide a precise, generative, and flexible solution for <strong>3D drag-based editing</strong>.
              </font>

              <!-- <br>All testing images shown below are never seen by the model in training. -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2>
      </div>
    </div>
  </section> -->

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <!-- <div id="results-carousel" class="carousel results-carousel"> -->

        <div class="columns is-centered has-text-centered">
          <div id="carousel" class="results-carousel">
            <!-- <div class="item" align="center"> -->
            <!-- <img src="static/images/teaser.png" width="100%" alt="overview_image"> -->
            <img src="static/images/teaser.png" width="100%" alt="overview_image">
            <div class="content has-text-justified">
              <p>
                <b>MVDrag3D</b> provides a precise, generative, and flexible solution for 3D drag-based editing, 
                supporting more versatile editing effects across various object categories and 3D representations.
              </p>
              <!-- </div> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">

    <div class="container is-max-desktop">

      <div class="container is-max-desktop">

        <section class="section">
          <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                  <p>
                    Drag-based editing has become popular in 2D content creation, driven by the capabilities of image generative models. However, extending this technique to 3D remains a challenge. 
                    Existing 3D drag-based editing methods, whether employing explicit spatial transformations or relying on implicit latent optimization within limited-capacity 3D generative models, 
                    fall short in handling significant topology changes or generating new textures across diverse object categories. 
                    To overcome these limitations, we introduce MVDrag3D, a novel framework for more flexible and creative drag-based 3D editing that leverages multi-view generation and reconstruction priors.
                    At the core of our approach is the usage of a multi-view diffusion model as a strong generative prior to perform consistent drag editing over multiple rendered views, which is followed by a reconstruction model that reconstructs 3D Gaussians of the edited object.
                    While the initial 3D Gaussians may suffer from misalignment between different views, we address this via view-specific deformation networks that adjust the position of Gaussians to be well aligned.
                    In addition, we propose a multi-view score function that distills generative priors from multiple views to further enhance the view consistency and visual quality. Extensive experiments demonstrate that MVDrag3D provides a precise, generative, and flexible solution for 3D drag-based editing, supporting more versatile editing effects across various object categories and 3D representations.
                  </p>
                </div>
                <div></div>

                <!-- <div align="center" style="margin-top:10px;" style="margin-bottom:40px;">
                  <img style='height: auto; width: 100%; object-fit: contain' src="static/images/overview.png">
                </div>
                <div class="content has-text-justified">
                  <p>
                    We propose to first learn a 3D latent space, where a monocular image is encoded into the
                    KL-regularized
                    latent space.
                    The encoded 3D latent is decoded by a 3D-aware DiT transformer, and up-sampled towards a high-res
                    tri-plane for rendering supervisions.
                    In the second stage, we perform efficient conditional diffusion learning over the compact latent
                    space.
                  </p>
                </div> -->

              </div>
            </div>

            <img style='height: auto; width: 100%; object-fit: contain' src="static/images/overview.png">
            <div class="content has-text-justified">
            <p>
              <strong>The overall architecture of MVDrag3D.</strong>
              Given a 3D model and multiple pairs of 3D dragging points, we first render the model into four orthogonal views, each with corresponding projected dragging points. 
              Then, to ensure consistent dragging across these views, we define a multi-view guidance energy within a multi-view diffusion model. 
              The resulting dragged images are used to regress an initial set of 3D Gaussians. 
              Our method further employs a two-stage optimization process: first, a deformation network adjusts the positions of the Gaussians for improved geometric alignment, 
              followed by image-conditioned multi-view score distillation to enhance the visual quality of the final output.
            </p>
            </div>

      </div>
  </section>



        <div class="columns is-centered">
          <!-- Matting. -->
          <div class="column is-full-width">
            <h2 class="title is-3" style="text-align: center;">Video Demo</h2>
            <div class="columns is-centered">
              <div class="column content">
                <!-- <p>
                  We showcase the reenactment comparison of our method against IDE-3D.
                  Given IDE-3D's segmentation-based nature, utilizing a reference identity with a different
                  shape unavoidably
                  leads to change in the face layout.
                  Nevertheless, Gaussian3Diff integrates a disentangled identity and expression modeling,
                  facilitated by the
                  underlying 3DMM, ensuring the preservation of the input identity through the reeactment
                  process.
                </p> -->

                <div style="display: flex; margin: 0 auto;">

                  <div>
                    <video width="100%" controls loop muted>
                      <source src="static/videos/video.mp4"
                        type="video/mp4">
                    </video>
                  </div>

                </div>

                
              </div>

            </div>
          </div>
        </div>
      
        <br>
  <!-- Concurrent Work. -->
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">Related Links</h2>

      <div class="content has-text-justified">
        <p>
          Our work is inspired by the following work:
        </p>
        <p>
          <a href="https://mv-dream.github.io/">MVDream</a> introduce a text-conditioned multi-view diffusion model, 
          which can generate consistent multi-view images from a given text prompt.
        </p>
        <p>
          <a href="https://image-dream.github.io/">ImageDream</a> introduce a image-conditioned multi-view diffusion model.
        </p>
        <p>
          <a href="https://github.com/3DTopia/LGM/">LGM</a> introduces a large-scale 3D Gaussian reconstruction model from four views.
        </p>
      </div>
    </div>
  </div>
  <!--/ Concurrent Work. -->

  </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
  @article{chen2024mvdrag3d,
  title={MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors},
  author={Chen, Honghua and Lan, Yushi and Chen, Yongwei and Zhou, Yifan and Pan, Xingang},
  journal={arXiv preprint arXiv:2410.16272},
  year={2024}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> -->
        <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <!-- <p> -->
            <!-- This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
            <!-- </p> -->
            <p>
              We thank <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> for sharing this website
              template.
              <!-- Please remember to remove the analytics code included in the header of the website which -->
              <!-- you do not want on your website. -->
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
